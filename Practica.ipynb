{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado de Tópicos\n",
    "Es una técnica para tratar documentos que no tienen alguna categorización, y asume que cada documento es una mezcla aleatorias de categorías o tópicos.\n",
    "\n",
    "Un tópico en el contexto de modelado de tópicos es una distribución de probabilidades de palabras para un conjunto, e indica la probabilidad que una palabra aparezca en un documento sobre un tópico en particular\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uilidad\n",
    "Puede ser usado para clasificar documentos similares\n",
    "Mejorar la indexación de texto y los métodos de recuperación de la información\n",
    "Encontrar patrones repetitivos que pueden derivar de la estructura del texto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "Hay dos métodos de aprendizaje automático con las iniciales LDA:\n",
    "    1. Asignación de Dirichlet latente, que es un método de modelado\n",
    "    2. Análisis discriminante lineal, que es un método de clasificación\n",
    "    \n",
    "No tienen relación, excepto por el hecho de que las iniciales LDA pueden referirse a cualquiera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA pertenece a una clase de modelos que son llamados modelos generativos ya que tienen una especie de fábula, \n",
    "que explica cómo se generaron los datos. Esta historia es generativa a una simplificación de la realidad, por supuesto,\n",
    "para hacer más fácil el aprendizaje de la máquina. En primer lugar crear temas mediante la asignación de los pesos \n",
    "de probabilidad a las palabras. cada tema será asignar diferentes pesos a diferentes palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo:\n",
    "Asignar alta probabilidad de que la palabra \"variable\" y una baja probabilidad a la palabra\n",
    "\"Ebrio\". \n",
    "Cuando se desea generar un nuevo documento, primero elegimos los temas que\n",
    "utilizará y luego mezclar palabras de estos temas.\n",
    "\n",
    "Por ejemplo, supongamos que tenemos sólo tres temas que tratan sobre los libros:\n",
    "\n",
    "• Aprendizaje automático\n",
    "\n",
    "• Python\n",
    "\n",
    "• Horneando\n",
    "\n",
    "Para cada tema, tenemos una lista de palabras asociadas a ella. Este libro será una\n",
    "mezcla de los dos primeros temas, tal vez 50 por ciento cada uno. La mezcla no necesita\n",
    "a ser igual, sino que también puede ser una fracción de 70/30. \n",
    "\n",
    "En este modelo, el orden de las palabras no importa. Se trata de una bolsa de palabras, porque el hecho de saber que las palabras se utiliza en un documento y sus frecuencias son suficientes para tomar decisiones de aprendizaje automático.\n",
    "\n",
    "En el mundo real, no sabemos lo que son los temas. Nuestra tarea es tomar una colección de texto y aplicar ingeniería inversa a esta fábula con el fin de descubrir qué temas están fuera, allí y al mismo tiempo averiguar qué temas utiliza cada documento.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
